import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.util.LongAccumulator

object SparkAccumulatorExample {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName("AccumulatorExample").setMaster("local[*]")
    val sc = new SparkContext(conf)

    val data = Array(1, 2, 3, 4, 5)
    val rdd = sc.parallelize(data)

    // Correct approach using Accumulator
    val counter: LongAccumulator = sc.longAccumulator("Counter Accumulator")

    rdd.foreach(x => counter.add(x))

    println("Counter value: " + counter.value)
    
    sc.stop()
  }
}
